{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  *<font color='purple'>Variation of a company's LinkedIn likes with days of the week.</font>*\n",
    "***\n",
    "### *Ultimately, the goal of brands on LinkedIn is to be able to engage with their customers or potential customers and to promote a message. Thus, it becomes imperative knowing when potential custumers are likeley to be interested in taking a look at their LinkedIn pages. Knowing when users are engaging and interacting with company's page can be crucial to getting the most effective message across. <br> <br> The goal of this project is to determine how a company's LinkedIn page likes varies from one day of the week to the other and if a mathematical function could be used to approximate such variation. <br> <br> The analysis is for top ten companies selected from Fortune 500, in addition to a few other very popular social media companies. <p>Result indicates that polynomial of second oder (quadratic) describes the relationship <p> Data is from the link: https://thedataincubator.us8.list-manage.com/subscribe/confirm?u=70e04e2160786cdebf3df2567&id=fbf1336bda&e=b835ffc04e*\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import time\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Reads the csv data and adds new columns containing the week and month of each row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"temp_datalab_records_linkedin_company.csv\",low_memory=False)\n",
    "df[\"as_of_date\"] = pd.to_datetime(df[\"as_of_date\"],format=\"%Y-%m-%d\")\n",
    "df['day_of_week'] = df['as_of_date'].apply(lambda x: x.weekday()) # get the weekday index\n",
    "df['day_of_week'] = df['day_of_week'].apply(lambda x: calendar.day_name[x])\n",
    "df['month'] = df.as_of_date.dt.month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get change in likes where two successive dates are consencutive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_change_in_likes(df):\n",
    "    #converts dates to ordinal for easy computation\n",
    "    df['ordinal_date'] = df['as_of_date'].apply(lambda x: x.toordinal())\n",
    "    df[\"day_difference\"] = np.nan\n",
    "    df[\"like_difference\"] = np.nan\n",
    "    df[\"employees_on_platform_difference\"] = np.nan\n",
    "    row_iterator = df.iterrows()\n",
    "    _, row = next(row_iterator)  # take first item from row_iterator\n",
    "    for i, _next in row_iterator:\n",
    "        current_row = row['ordinal_date']\n",
    "        current_likes = row['followers_count']\n",
    "        current_employ_likes = row['employees_on_platform']\n",
    "        \n",
    "        next_row = _next['ordinal_date']\n",
    "        next_likes = _next['followers_count']\n",
    "        next_employ_likes = _next['employees_on_platform']\n",
    "        current_and_next_low_list = [current_row,next_row]\n",
    "        row = _next\n",
    "        #Checks if two neighboring dates are consecutive\n",
    "        if max(current_and_next_low_list) - min(current_and_next_low_list) == \\\n",
    "        len(current_and_next_low_list) - 1:\n",
    "            df.loc[i, 'day_difference'] = next_row - current_row\n",
    "            df.loc[i, \"like_difference\"] = next_likes - current_likes\n",
    "            df.loc[i, \"employees_on_platform_difference\"] = \\\n",
    "            abs(next_employ_likes - current_employ_likes)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    # selects rows where day_difference is not null. They satisfy what we want\n",
    "    df = df[(df[\"day_difference\"].notnull())]\n",
    "    df = df[(df[\"like_difference\"].notnull())]\n",
    "    df = df[(df[\"employees_on_platform_difference\"].notnull())]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fits and plots the data and quadratic fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "\n",
    "def quadratic_fit(x,a,b,c):\n",
    "    return np.array(a+b*x+c*x**2)\n",
    "groups = df.groupby(\"company_name\")\n",
    "#company = \"Walmart\" # put the name of company you want\n",
    "companies = [\"Facebook\",\"Walmart\",\"Google\",\"Amazon\",\"Apple\",\"AT&T\",\"CVS Health\",\"Twitter\",\\\n",
    "             \"General Motors\",\"UnitedHealth Group\",\"McKesson\",\"ExxonMobil\",\"LinkedIn\"]\n",
    "for company in companies:\n",
    "    df1 = groups.get_group(company)\n",
    "    df1 = df1[df1['followers_count']>=1]\n",
    "    df1 = get_change_in_likes(df1)\n",
    "    df1 = df1.groupby(\"day_of_week\")\n",
    "    #get the days and sort them in the right order\n",
    "    weekdays = df1.groups.keys()\n",
    "    days = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "    days_abbrev = [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "    ordered_weekdays = sorted(weekdays, key=days.index)\n",
    "    followers_weekly_avg = []\n",
    "    employ_likes_weekly_avg = []\n",
    "    for day in ordered_weekdays:\n",
    "        d = df1.get_group(day)\n",
    "        mean_following = d.like_difference.mean()\n",
    "        mean_employ_likes =d.employees_on_platform_difference.mean()\n",
    "        followers_weekly_avg.append(mean_following)\n",
    "        employ_likes_weekly_avg.append(mean_employ_likes)\n",
    "    points = [1,2,3,4,5,6,7] #the days of the week\n",
    "    P0 = np.array([1,1,1])\n",
    "    coeffs, matcov = curve_fit(quadratic_fit, points, followers_weekly_avg, P0)\n",
    "    x = np.linspace(0.5,7,100)\n",
    "    y = quadratic_fit(x,*coeffs)\n",
    "    #plots the data\n",
    "    plt.plot(points,followers_weekly_avg,\"k*\",x,y,\"r\")\n",
    "    plt.xticks(points, days_abbrev)\n",
    "    plt.title(\"Quadratic fit to \"+company+\" LinkedIn page likes\",size=12,weight ='bold')\n",
    "    plt.xlabel(\"day of the week\",size=8,weight ='bold')\n",
    "    plt.ylabel(\"Average number of new LinkedIn likes\",size=8,weight ='bold')\n",
    "    plt.legend([\"Data\",\"Fit\"])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(company+\".png\",bbox_inches=\"tight\", dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  *<font color='purple'>Plots below shows the quadratic relationship between days of the week and average number of new LinkedIn likes </font>*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Facebook.png\">\n",
    "<img src=\"Walmart.png\">\n",
    "<img src=\"Google.png\">\n",
    "<img src=\"Amazon.png\">\n",
    "<img src=\"Apple.png\">\n",
    "<img src=\"AT&T.png\">\n",
    "<img src=\"CVS Health.png\">\n",
    "<img src=\"Twitter.png\">\n",
    "<img src=\"General Motors.png\">\n",
    "<img src=\"UnitedHealth Group.png\">\n",
    "<img src=\"McKesson.png\">\n",
    "<img src=\"ExxonMobil.png\">\n",
    "<img src=\"LinkedIn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "   ## *As can be see, increase in likes peaks at midweek. So, those companies will better engage with potential customers if they advertise on LinkedIn in the midweek.* <br>\n",
    "## *This reference: https://mashable.com/2010/10/28/facebook-activity-study/#RX35mrR835q8, done using facebook data supports the result from this analysis.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
